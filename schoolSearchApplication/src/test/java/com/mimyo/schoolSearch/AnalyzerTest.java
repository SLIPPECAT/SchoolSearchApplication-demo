package com.mimyo.schoolSearch;

import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.core.KeywordAnalyzer;
import org.apache.lucene.analysis.core.WhitespaceAnalyzer;
import org.apache.lucene.analysis.email.UAX29URLEmailAnalyzer;
import org.apache.lucene.analysis.ko.KoreanAnalyzer;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.analysis.tokenattributes.*;
import org.junit.jupiter.api.DisplayName;
import org.junit.jupiter.api.Test;
import org.springframework.util.Assert;

import java.io.IOException;
import java.io.StringReader;
import java.util.ArrayList;
import java.util.List;

public class AnalyzerTest {

    @Test
    @DisplayName("ë¶„ì„ëœ í† í° ê²°ê³¼ê°€ 'ì‹ ìƒ', 'ì´ˆë“±', 'í•™êµ' ì¸ì§€ í…ŒìŠ¤íŠ¸")
    void koreanAnalyzerTest () throws IOException {
        String text1 = "ì‹ ìƒê³„ì´ˆë“±í•™êµ";
        String text2 = "ì‹ ìƒë„ì´ˆë“±í•™êµ";

        Analyzer analyzer = new KoreanAnalyzer();

        TokenStream tokenStream1 = analyzer.tokenStream("field", new StringReader(text1));
        tokenStream1.reset();;

        List<String> analyzedText1Tokens = new ArrayList<>();
        while(tokenStream1.incrementToken()) {
            CharTermAttribute charTermAttribute = tokenStream1.addAttribute(CharTermAttribute.class);
            analyzedText1Tokens.add(charTermAttribute.toString());
        }
        tokenStream1.close();

        TokenStream tokenStream2 = analyzer.tokenStream("field", new StringReader(text2));
        tokenStream2.reset();;
        List<String> analyzedText2Tokens = new ArrayList<>();
        while(tokenStream1.incrementToken()) {
            CharTermAttribute charTermAttribute = tokenStream2.addAttribute(CharTermAttribute.class);
            analyzedText2Tokens.add(charTermAttribute.toString());
        }
        tokenStream2.close();

        Assert.isTrue(analyzedText1Tokens.containsAll(List.of("ì‹ ìƒ", "ì´ˆë“±", "í•™êµ")), "ë¶„ì„ ê²°ê³¼ê°€ ë‹¤ë¦…ë‹ˆë‹¤.");
        Assert.isTrue(analyzedText2Tokens.containsAll(List.of("ì‹ ìƒ", "ì´ˆë“±", "í•™êµ")), "ë¶„ì„ ê²°ê³¼ê°€ ë‹¤ë¦…ë‹ˆë‹¤.");
    }

    @Test
    @DisplayName("Analyzer ë¶„ì„ ê²°ê³¼ ì¶œë ¥")
    public void analyzerTest () throws IOException {
        // ë¶„ì„í•  ë‚´ìš©
        String text = "ì•„ì´ìœ ê°€ ë¶€ë¦…ë‹ˆë‹¤. ë¸”ë£¨ë°. IU is singing strawberry.";
//        String text = "ì  ì§€ëŠ” ë¹ ë¥´ê²Œ ë“œë˜ê³¤ ë²„ìŠ¤íŠ¸ì— ì„±ê³µí•œ ë’¤ ë°”ë¡ ìœ¼ë¡œ í–¥í–ˆë‹¤. íƒˆë¦¬ì•¼ì˜ ê¶ê·¹ê¸°ë¥¼ í†µí•´ ë°”ë¡ ì„ ê³„ì† ì¹˜ë‹¤ê°€ DKê°€ ì „íˆ¬ë¥¼ ì‹œì‘í–ˆë‹¤. ì  ì§€ëŠ” êµ‰ì¥íˆ ìœ„í—˜í•œ ìƒí™©ì—ì„œ íƒ‘ íƒ€ì›Œê¹Œì§€ ì „ì¥ì„ ìœ ì¸í•´ ë“ì ì„ ë”°ëƒˆë‹¤.";
        // ê³µë°± ê¸°ë°˜ ë¶„ì„ê¸°ë¥¼ ì´ìš©
        Analyzer whitespaceAnalyzer = new WhitespaceAnalyzer();
        analyzerTest(text, whitespaceAnalyzer);
//        Analyzer standardAnalyzer = new StandardAnalyzer();
//        analyzerTest(text, standardAnalyzer);
//        Analyzer keywordAnalyzer = new KeywordAnalyzer();
//        analyzerTest(text, keywordAnalyzer);
//        Analyzer koreanAnalyzer = new KoreanAnalyzer();
//        analyzerTest(text, koreanAnalyzer);
    }

    public static void analyzerTest(String text, Analyzer analyzer) throws IOException {
        String analyzerClassName = analyzer.getClass().getName();

        // í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•œë‹¤. -> TokenStream ì„ ë°˜í™˜
        TokenStream tokenStream = analyzer.tokenStream("field", new StringReader(text));

//         ë¶„ì„ëœ í† í°ì˜ ì†ì„± ê°’ì„ ì„¤ì •í•œë‹¤.
        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);
        tokenStream.reset();

        System.out.println(analyzerClassName + " ë¥¼ ì´ìš©í•œ ë¶„ì„");
        while(tokenStream.incrementToken()) {
            System.out.print(charTermAttribute.toString() + " ğŸ”» ");
        }

        // TokenStreamì˜ ê° ì†ì„±ì— ì ‘ê·¼í•˜ê¸° ìœ„í•œ Attribute ì„ ì–¸
//        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);
//        OffsetAttribute offsetAttribute = tokenStream.addAttribute(OffsetAttribute.class);
//        PositionIncrementAttribute positionIncrementAttribute = tokenStream.addAttribute(PositionIncrementAttribute.class);
//        PositionLengthAttribute positionLengthAttribute = tokenStream.addAttribute(PositionLengthAttribute.class);
//        TermToBytesRefAttribute termToBytesRefAttribute = tokenStream.addAttribute(TermToBytesRefAttribute.class);
//        TypeAttribute typeAttribute = tokenStream.addAttribute(TypeAttribute.class);
//
//        // TokenStream ë°˜ë³µí•˜ì—¬ ì¶œë ¥
//        tokenStream.reset();
//        while (tokenStream.incrementToken()) {
//            System.out.println("Token: " + charTermAttribute.toString());
//            System.out.println("  Offset: " + offsetAttribute.startOffset() + "-" + offsetAttribute.endOffset());
//            System.out.println("  Position increment: " + positionIncrementAttribute.getPositionIncrement());
//            System.out.println("  Position length: " + positionLengthAttribute.getPositionLength());
//            System.out.println("  Term bytes: " + termToBytesRefAttribute.getBytesRef().utf8ToString());
//            System.out.println("  Type: " + typeAttribute.type());
//            System.out.println();
//        }

        tokenStream.close();
    }

}